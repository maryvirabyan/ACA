{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNV45oCVxOX0YwxzHo64+rq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryvirabyan/ACA/blob/main/DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYVWa9IyZ9Vc"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "  def feedforward(self, input):\n",
        "    pass\n",
        "  def backpropogation(self, output_gradient, learning_rate):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class DenseLayer(Layer):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    self.weights = np.random.randn(output_size, input_size)\n",
        "    self.bias = np.random.randn(output_size, 1)\n",
        "  def feedforward(self, input):\n",
        "    self.input = input\n",
        "    return np.dot(self.weights, self.input) + self.bias\n",
        "  def backpropogation(self, output_gradient, learning_rate):\n",
        "    weights_gradient = np.dot(output_gradient, self.input.T)\n",
        "    self.weights -= learning_rate* weights_gradient\n",
        "    self.bias -= learning_rate * output_gradient\n",
        "    return np.dot(self.weights.T, output_gradient)"
      ],
      "metadata": {
        "id": "GUlljfZtafYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def feedforward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(self.input)\n",
        "\n",
        "    def backpropogation(self, output_gradient, learning_rate):\n",
        "        return np.multiply(output_gradient, self.activation_prime(self.input))"
      ],
      "metadata": {
        "id": "ZJQxHiM8chB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / np.size(y_true)"
      ],
      "metadata": {
        "id": "yCqoCVdydOTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid(Activation):\n",
        "    def __init__(self):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x))\n",
        "\n",
        "        def sigmoid_prime(x):\n",
        "            s = sigmoid(x)\n",
        "            return s * (1 - s)\n",
        "\n",
        "        super().__init__(sigmoid, sigmoid_prime)\n",
        "class ReLU(Activation):\n",
        "    def __init__(self):\n",
        "        def relu(x):\n",
        "            return np.maximum(0, x)\n",
        "\n",
        "        def relu_prime(x):\n",
        "            return np.where(x > 0, 1, 0)\n",
        "\n",
        "        super().__init__(relu, relu_prime)"
      ],
      "metadata": {
        "id": "XA_evUsAdLUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNetwork:\n",
        "    @staticmethod\n",
        "    def predict(network, input):\n",
        "        output = input\n",
        "        for layer in network:\n",
        "            output = layer.feedforward(output)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def train(network, loss, loss_prime, x_train, y_train, epochs=1000, learning_rate=0.01, verbose=True):\n",
        "        for e in range(epochs):\n",
        "            error = 0\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                output = DenseNetwork.predict(network, x)\n",
        "                error += loss(y, output)\n",
        "                grad = loss_prime(y, output)\n",
        "                for layer in reversed(network):\n",
        "                    grad = layer.backpropagation(grad, learning_rate)\n",
        "            error /= len(x_train)\n",
        "            if verbose:\n",
        "                print(f\"{e + 1}/{epochs}, error={error}\")\n"
      ],
      "metadata": {
        "id": "ZyUgsolqeR4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "X = np.reshape([[0, 0], [0, 1], [1, 0], [1, 1]], (4, 2, 1))\n",
        "Y = np.reshape([[0], [1], [1], [0]], (4, 1, 1))\n",
        "\n",
        "network = [\n",
        "    DenseLayer(2, 3),\n",
        "    ReLU(),\n",
        "    DenseLayer(3, 1),\n",
        "    Sigmoid()\n",
        "]\n",
        "train(network, mse, mse_prime, X, Y, epochs=100, learning_rate=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh-9y5yZna5L",
        "outputId": "84486129-885f-4bf4-9584-f81b6184fb93"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/100, error=0.2889670450377246\n",
            "2/100, error=0.2783791847696998\n",
            "3/100, error=0.2726720685382807\n",
            "4/100, error=0.26750546738374964\n",
            "5/100, error=0.2628049492937255\n",
            "6/100, error=0.25850003985534054\n",
            "7/100, error=0.255633693512533\n",
            "8/100, error=0.2539000413918794\n",
            "9/100, error=0.2522752843995194\n",
            "10/100, error=0.2507501579601548\n",
            "11/100, error=0.24931562301288046\n",
            "12/100, error=0.24796295739213806\n",
            "13/100, error=0.2466838238570061\n",
            "14/100, error=0.24547031781132508\n",
            "15/100, error=0.24431499779620633\n",
            "16/100, error=0.2432109017163464\n",
            "17/100, error=0.2421515515365816\n",
            "18/100, error=0.24113094889931758\n",
            "19/100, error=0.2401435638006622\n",
            "20/100, error=0.2391843181477799\n",
            "21/100, error=0.2382485657188484\n",
            "22/100, error=0.23736194809582606\n",
            "23/100, error=0.2365587780570001\n",
            "24/100, error=0.23568381759496826\n",
            "25/100, error=0.23481541042687115\n",
            "26/100, error=0.23395091474879515\n",
            "27/100, error=0.23308795890631528\n",
            "28/100, error=0.23222442124747258\n",
            "29/100, error=0.2313584111056603\n",
            "30/100, error=0.23048825096490086\n",
            "31/100, error=0.2296124598218887\n",
            "32/100, error=0.22890945600641452\n",
            "33/100, error=0.22805604784828484\n",
            "34/100, error=0.22716126923906946\n",
            "35/100, error=0.22625485814846785\n",
            "36/100, error=0.22533626372451956\n",
            "37/100, error=0.22440504019763105\n",
            "38/100, error=0.22346083924430465\n",
            "39/100, error=0.2225034029948576\n",
            "40/100, error=0.2216853659589978\n",
            "41/100, error=0.2208223256418113\n",
            "42/100, error=0.21982097311176618\n",
            "43/100, error=0.21880488930129333\n",
            "44/100, error=0.21777431451252466\n",
            "45/100, error=0.21672953745975063\n",
            "46/100, error=0.21567089298488312\n",
            "47/100, error=0.21459876002150385\n",
            "48/100, error=0.21361800156134822\n",
            "49/100, error=0.21273073460831357\n",
            "50/100, error=0.21160803958438135\n",
            "51/100, error=0.2104733536058728\n",
            "52/100, error=0.20932733017242303\n",
            "53/100, error=0.20762203060557832\n",
            "54/100, error=0.2076654968896877\n",
            "55/100, error=0.20700638027629045\n",
            "56/100, error=0.20550084871137847\n",
            "57/100, error=0.20529974511077784\n",
            "58/100, error=0.20486754453645517\n",
            "59/100, error=0.203612810290784\n",
            "60/100, error=0.20317004883057851\n",
            "61/100, error=0.20237288838586437\n",
            "62/100, error=0.20184007092205214\n",
            "63/100, error=0.20043279878190665\n",
            "64/100, error=0.2005599847388974\n",
            "65/100, error=0.20012452037186632\n",
            "66/100, error=0.19894876738375217\n",
            "67/100, error=0.19852902386978458\n",
            "68/100, error=0.19742828051453903\n",
            "69/100, error=0.1975466057193094\n",
            "70/100, error=0.19624696592384755\n",
            "71/100, error=0.19612686839964275\n",
            "72/100, error=0.19510773944682708\n",
            "73/100, error=0.19510422397838414\n",
            "74/100, error=0.19388909302255702\n",
            "75/100, error=0.1938448914349578\n",
            "76/100, error=0.1926954742419444\n",
            "77/100, error=0.1929654640961201\n",
            "78/100, error=0.19182780184709125\n",
            "79/100, error=0.19165769241324662\n",
            "80/100, error=0.19048818150669017\n",
            "81/100, error=0.19077470198815777\n",
            "82/100, error=0.1901303700817533\n",
            "83/100, error=0.18911974252104824\n",
            "84/100, error=0.18937667051894067\n",
            "85/100, error=0.188028158649211\n",
            "86/100, error=0.18865363244233418\n",
            "87/100, error=0.18769506655763438\n",
            "88/100, error=0.18679920284544577\n",
            "89/100, error=0.1872597354417032\n",
            "90/100, error=0.1858643815809678\n",
            "91/100, error=0.186557221285396\n",
            "92/100, error=0.18569640535290594\n",
            "93/100, error=0.1848935945682405\n",
            "94/100, error=0.18524398013081889\n",
            "95/100, error=0.1840954763825668\n",
            "96/100, error=0.18422375536605007\n",
            "97/100, error=0.18413163791386716\n",
            "98/100, error=0.18339612426185903\n",
            "99/100, error=0.18271052776592678\n",
            "100/100, error=0.1833088510793944\n"
          ]
        }
      ]
    }
  ]
}